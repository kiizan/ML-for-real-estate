{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "db_url = 'postgresql://postgres:post@localhost:5432/m_l_m'\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "tables = ['annonce', 'city', 'equipment', 'annonce_equipment']\n",
    "dataframes = {table: pd.read_sql_table(table, engine) for table in tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tables for analysis\n",
    "ads = dataframes['annonce']\n",
    "ads_equips = dataframes['annonce_equipment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>equipment_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1362</th>\n",
       "      <th>1363</th>\n",
       "      <th>1364</th>\n",
       "      <th>1365</th>\n",
       "      <th>1366</th>\n",
       "      <th>1367</th>\n",
       "      <th>1368</th>\n",
       "      <th>1369</th>\n",
       "      <th>1370</th>\n",
       "      <th>1371</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annonce_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "equipment_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "annonce_id                                                                ...   \n",
       "1              1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2              0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3              0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4              0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "5              0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "equipment_id  1362  1363  1364  1365  1366  1367  1368  1369  1370  1371  \n",
       "annonce_id                                                                \n",
       "1              0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2              0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3              0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4              0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "5              0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1371 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "ads = ads[ads['price'] != 'PRIX NOT SPECIFIED']\n",
    "ads['price'] = pd.to_numeric(ads['price'], errors='coerce')\n",
    "ads.dropna(subset=['price'], inplace=True)\n",
    "\n",
    "ads['year'] = pd.to_datetime(ads['datetime']).dt.year\n",
    "ads['month'] = pd.to_datetime(ads['datetime']).dt.month\n",
    "ads['day'] = pd.to_datetime(ads['datetime']).dt.day\n",
    "\n",
    "# Encode categorical variables\n",
    "ads = pd.get_dummies(ads, columns=['city_id'], drop_first=True)\n",
    "\n",
    "# Create binary variables for equipment presence\n",
    "ads_equips['equiped'] = 1\n",
    "equip_binary = ads_equips.pivot(index='annonce_id', columns='equipment_id', values='equiped').fillna(0)\n",
    "ads = ads.merge(equip_binary, left_on='id', right_index=True, how='left')\n",
    "equip_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical variables using Min-Max Scaling\n",
    "scaler = MinMaxScaler()  \n",
    "numerical_vars = ['price', 'nb_rooms', 'nb_baths', 'surface_area']\n",
    "ads[numerical_vars] = scaler.fit_transform(ads[numerical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "corr_matrix = ads[numerical_vars].corr()\n",
    "\n",
    "# Visualize Correlation Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical predictors for VIF\n",
    "X = ads[['nb_rooms', 'nb_baths', 'surface_area', 'year', 'month']]  # Add more features if necessary\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select independent variables (features) and target variable (price)\n",
    "X = ads[['nb_rooms', 'nb_baths', 'surface_area'] + list(ads.filter(like='city_id_'))]\n",
    "y = ads['price']\n",
    "\n",
    "# Convert column names to string and ensure no hidden issues\n",
    "X.columns = [str(col) for col in X.columns] \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Ridge regression model\n",
    "ridge_regressor = Ridge(alpha=1.0)  # You can adjust alpha for regularization strength\n",
    "ridge_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Visualize residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_test, residuals, color='#FF7200')\n",
    "plt.axhline(y=0, color='#5C00FF', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals of Ridge Regression')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "sns.histplot(residuals, kde=True, color='#00D4FF')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for normality of residuals\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data (removing the 'year' feature)\n",
    "X = ads[['nb_rooms', 'nb_baths', 'surface_area'] + list(ads.filter(like='city_id_'))]\n",
    "y = ads['price']\n",
    "\n",
    "# Convert all column names to strings explicitly to avoid the 'quoted_name' and 'str' issue\n",
    "X.columns = [str(col) for col in X.columns]\n",
    "\n",
    "# Ensure all column types in X are numeric, and convert categorical booleans to 0 or 1 (if applicable)\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models initialization\n",
    "ridge_regressor = Ridge(alpha=1.0)\n",
    "lasso_regressor = Lasso(alpha=1.0)\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# List of models to compare\n",
    "models = {\n",
    "    \"Ridge Regression\": ridge_regressor,\n",
    "    \"Lasso Regression\": lasso_regressor,\n",
    "    \"Random Forest\": rf_regressor,\n",
    "    \"Gradient Boosting\": gb_regressor\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    mse, r2 = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {\"MSE\": mse, \"R2\": r2}\n",
    "\n",
    "# Print results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name} - MSE: {result['MSE']:.4f}, RÂ²: {result['R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and their hyperparameters\n",
    "models = {\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Define the parameter grids\n",
    "param_grids = {\n",
    "    \"Ridge Regression\": {\n",
    "        \"alpha\": [0.1, 1, 10, 100]\n",
    "    },\n",
    "    \"Lasso Regression\": {\n",
    "        \"alpha\": [0.1, 1, 10, 100]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to perform GridSearchCV and print the best results\n",
    "def tune_model(model_name, model, param_grid, X_train, y_train):\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best MSE for {model_name}: {-grid_search.best_score_}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Tuning the models\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    param_grid = param_grids[model_name]\n",
    "    best_model = tune_model(model_name, model, param_grid, X_train, y_train)\n",
    "    best_models[model_name] = best_model\n",
    "\n",
    "# After tuning, evaluate the best models on the test set\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse:.4f}, RÂ²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Random Forest model\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_rf = y_test - y_pred_rf\n",
    "\n",
    "# Plot Residuals vs True Values (Scatter Plot)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_test, residuals_rf, color='#00FFFF')\n",
    "plt.axhline(y=0, color='#2B00FF', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals of Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Plot Histogram of Residuals\n",
    "sns.histplot(residuals_rf, kde=True, color='#FF0067')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot to check Normality of Residuals\n",
    "stats.probplot(residuals_rf, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set using Gradient Boosting\n",
    "y_pred_gb = gb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_gb = y_test - y_pred_gb\n",
    "\n",
    "# Scatter plot of residuals\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_test, residuals_gb, color='#7200FF')\n",
    "plt.axhline(y=0, color='#0019FF', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals of Gradient Boosting')\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals for Gradient Boosting\n",
    "sns.histplot(residuals_gb, kde=True, color='springgreen')\n",
    "plt.title('Distribution of Residuals - Gradient Boosting')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for normality of residuals (Gradient Boosting)\n",
    "stats.probplot(residuals_gb, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals - Gradient Boosting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Why Random Forest?\n",
    "\n",
    "After evaluating multiple models (Ridge, Lasso, Random Forest, and Gradient Boosting), **Random Forest** was chosen based on its superior performance and robustness.\n",
    "\n",
    "- **Performance:** Random Forest achieved the _**lowest MSE (0.0013)**_ and the _**highest RÂ² (0.9418)**_, outperforming the other models.\n",
    "- **Non-linearity:** Random Forest captures complex, non-linear relationships, which is beneficial for this dataset.\n",
    "- **Robustness:** It is less prone to overfitting and handles noisy data well.\n",
    "- **Feature Importance:** Random Forest helps identify key predictors, improving model interpretability.\n",
    "- **Residuals:** The residuals were well-distributed around zero, indicating good generalization.\n",
    "\n",
    "For these reasons, **Random Forest** was selected as the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_regressor.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='#7D00FF')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Interpretation\n",
    "\n",
    "In the Random Forest model, the feature importance ranking shows that **'nb_rooms'** has the greatest influence on property price, followed by **'nb_baths'** and **'surface_area'**. This indicates:\n",
    "\n",
    "- **Number of rooms** (*`'nb_rooms'`*) is the most significant factor in predicting price, with more rooms generally leading to higher property values.\n",
    "- **Number of bathrooms** (*`'nb_baths'`*) and **surface area** (*`'surface_area'`*) have lesser importance but still contribute to price, with larger properties and more bathrooms being valued higher, though to a smaller extent than the number of rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x=y_test, y=y_pred_rf, lowess=True, color='cyan')\n",
    "plt.title(\"Regression Residual Plot\")\n",
    "plt.xlabel(\"True Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Analysis\n",
    "ads['has_elevator'] = ads[equip_binary.columns].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "X_clf = ads[['nb_rooms', 'nb_baths', 'surface_area']]\n",
    "y_clf = ads['has_elevator']\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "model_clf = RandomForestClassifier(random_state=42)\n",
    "model_clf.fit(X_train_clf, y_train_clf)\n",
    "y_pred_clf = model_clf.predict(X_test_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Classification\n",
    "print(classification_report(y_test_clf, y_pred_clf))\n",
    "print(\"Classification ROC-AUC:\", roc_auc_score(y_test_clf, model_clf.predict_proba(X_test_clf)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test_clf, model_clf.predict_proba(X_test_clf)[:, 1])\n",
    "plt.plot(fpr, tpr, label=f\"Random Forest (AUC = {roc_auc_score(y_test_clf, model_clf.predict_proba(X_test_clf)[:, 1]):.2f})\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ethical Considerations\n",
    "\n",
    "### 2.1. Bias in Data\n",
    "- **Urban vs. Rural Bias**: If the dataset contains more advertisements from urban areas, the models may not generalize well to rural contexts.\n",
    "- **Socioeconomic Factors**: Price predictions might inadvertently reflect societal inequalities (e.g., lower prices in certain neighborhoods due to historical biases).\n",
    "\n",
    "#### Mitigation:\n",
    "- Perform stratified sampling to ensure diverse representation in training data.\n",
    "- Include additional variables like average income or amenities to account for contextual factors.\n",
    "\n",
    "### 2.2. Transparency in Predictions\n",
    "- **Explainable AI**: Use tools like SHAP or LIME to explain model predictions, ensuring end-users understand why a particular prediction was made.\n",
    "- **Fairness in Classification**: Ensure the classification model does not disproportionately misclassify equipment presence in specific regions or demographics.\n",
    "\n",
    "#### Mitigation:\n",
    "- Perform fairness audits to evaluate disparate impact across groups.\n",
    "- Regularly monitor model performance in deployment to detect biases.\n",
    "\n",
    "### 2.3. Privacy Concerns\n",
    "- Ensure the dataset does not include personally identifiable information (PII) about advertisers or users.\n",
    "- If using geolocation data (e.g., city IDs), ensure it is anonymized.\n",
    "\n",
    "#### Mitigation:\n",
    "- Use pseudonymized or aggregated data when analyzing or deploying models.\n",
    "- Comply with data protection regulations like GDPR or CCPA.\n",
    "\n",
    "### 2.4. Ethical Use of Predictions\n",
    "- Predicted prices could influence the real estate market (e.g., price hikes). Ensure stakeholders use predictions responsibly.\n",
    "- Avoid using models for discriminatory practices, such as excluding certain demographics from targeted advertisements.\n",
    "\n",
    "#### Mitigation:\n",
    "- Clearly define and document acceptable use cases for the models.\n",
    "- Collaborate with domain experts to align model outcomes with ethical standards.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Empirical Steps for Ethical Monitoring\n",
    "1. **Bias Detection**:\n",
    "   - Calculate fairness metrics like disparate impact ratio to evaluate bias.\n",
    "   - Compare model performance across different subgroups (e.g., urban vs. rural).\n",
    "\n",
    "2. **Explainability Tools**:\n",
    "   - Implement SHAP for feature importance analysis:\n",
    "     ```python\n",
    "     import shap\n",
    "     explainer = shap.Explainer(model, X_test)\n",
    "     shap_values = explainer(X_test)\n",
    "     shap.summary_plot(shap_values, X_test)\n",
    "     ```\n",
    "\n",
    "3. **Regular Audits**:\n",
    "   - Set up a pipeline for periodic evaluation of deployed models to detect drift or new biases.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Note:\n",
    "By documenting the project comprehensively and addressing ethical considerations thoroughly, we ensure that the models are both robust and responsibly deployed. This approach fosters transparency, trust, and fairness in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
